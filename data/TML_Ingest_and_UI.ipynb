{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f22cc7e",
   "metadata": {},
   "source": [
    "# TML Database → matches.csv & points_sets_games.csv (UI)\n",
    "Aquest notebook baixa dades de **TML-Database** (GitHub) i construeix els fitxers:\n",
    "- `data/matches.csv`\n",
    "- `data/points_sets_games.csv`\n",
    "\n",
    "Inclou una **mini UI** per triar anys, incloure tornejos en curs i randomitzar l'orientació A/B.\n",
    "\n",
    "> ℹ️ Llicència: TML-Database es basa en Jeff Sackmann i s'ofereix amb condicions d'ús pròpies. Revisa la llicència del repo si l'ús és comercial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48fdadac",
   "metadata": {},
   "source": [
    "## 1) Dependències"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3b895e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Si falta ipywidgets, descomenta:\n",
    "# !pip install ipywidgets requests pandas numpy --quiet\n",
    "\n",
    "import os, io, requests, pandas as pd, numpy as np, datetime as dt\n",
    "from IPython.display import display, HTML\n",
    "try:\n",
    "    import ipywidgets as widgets\n",
    "except Exception as e:\n",
    "    print(\"ip ywidgets no disponible. Pots seguir executant amb la cel·la de funcions i crides manualment.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43435552",
   "metadata": {},
   "source": [
    "## 2) Funcions d'ingesta des de TML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e967437",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "RAW_BASE = \"https://raw.githubusercontent.com/Tennismylife/TML-Database/master\"\n",
    "\n",
    "def year_range(s: str):\n",
    "    s = str(s)\n",
    "    if \"-\" in s:\n",
    "        a,b = s.split(\"-\",1)\n",
    "        return list(range(int(a), int(b)+1))\n",
    "    return [int(s)]\n",
    "\n",
    "def fetch_csv(url: str) -> pd.DataFrame:\n",
    "    r = requests.get(url, timeout=60)\n",
    "    r.raise_for_status()\n",
    "    # TML files are comma-separated\n",
    "    return pd.read_csv(io.StringIO(r.text))\n",
    "\n",
    "def yyyymmdd_to_date(x):\n",
    "    try:\n",
    "        x = str(int(x)).strip()\n",
    "        return f\"{x[:4]}-{x[4:6]}-{x[6:8]}\"\n",
    "    except Exception:\n",
    "        return None\n",
    "        \n",
    "# --- PATCH: norm_surface robusta + typo \"coce\" arreglat a \"coerce\" ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def norm_surface(s):\n",
    "    if pd.isna(s):\n",
    "        return \"\"\n",
    "    try:\n",
    "        s = str(s).strip().lower()\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "    if \"hard\" in s: return \"hard\"\n",
    "    if \"clay\" in s: return \"clay\"\n",
    "    if \"grass\" in s: return \"grass\"\n",
    "    if \"carpet\" in s: return \"indoor-hard\"\n",
    "    return \"\"\n",
    "\n",
    "def map_level(lvl):\n",
    "    m = {\"G\":\"GS\", \"A\":\"ATP\", \"D\":\"Davis\", \"F\":\"Finals\"}\n",
    "    return m.get(str(lvl).strip(), str(lvl).strip())\n",
    "\n",
    "def yyyymmdd_to_date(x):\n",
    "    try:\n",
    "        x = str(int(x)).strip()\n",
    "        return f\"{x[:4]}-{x[4:6]}-{x[6:8]}\"\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "def build_from_tml(df: pd.DataFrame, seed: int = 2025, do_flip: bool = True):\n",
    "    cols_req = [\n",
    "        \"tourney_id\",\"tourney_name\",\"surface\",\"tourney_level\",\"tourney_date\",\"match_num\",\n",
    "        \"winner_id\",\"winner_ioc\",\"loser_id\",\"loser_ioc\",\"best_of\",\"round\",\"minutes\",\n",
    "        \"w_ace\",\"w_df\",\"w_svpt\",\"w_1stIn\",\"w_1stWon\",\"w_2ndWon\",\"w_SvGms\",\"w_bpSaved\",\"w_bpFaced\",\n",
    "        \"l_ace\",\"l_df\",\"l_svpt\",\"l_1stIn\",\"l_1stWon\",\"l_2ndWon\",\"l_SvGms\",\"l_bpSaved\",\"l_bpFaced\"\n",
    "    ]\n",
    "    for c in cols_req:\n",
    "        if c not in df.columns:\n",
    "            df[c] = np.nan\n",
    "\n",
    "    df[\"date\"] = df[\"tourney_date\"].apply(yyyymmdd_to_date)\n",
    "    df[\"surface_norm\"] = df[\"surface\"].apply(norm_surface)\n",
    "    df[\"level_norm\"] = df[\"tourney_level\"].apply(map_level)\n",
    "    df[\"indoor_flag\"] = (df[\"surface_norm\"]==\"indoor-hard\").astype(int)\n",
    "    df[\"best_of_5\"] = (pd.to_numeric(df[\"best_of\"], errors=\"coerce\")==5).astype(int)\n",
    "    df[\"minutes\"] = pd.to_numeric(df[\"minutes\"], errors=\"coerce\")\n",
    "    df[\"match_id\"] = df.apply(lambda r: f\"{r.get('tourney_id','')}_{r.get('match_num','')}_{r.get('date','')}\", axis=1)\n",
    "\n",
    "    rng = np.random.default_rng(seed)\n",
    "    flip = rng.integers(0,2, size=len(df)).astype(bool) if do_flip else np.zeros(len(df), dtype=bool)\n",
    "\n",
    "    player_a_id = df[\"winner_id\"].astype(str).where(~flip, df[\"loser_id\"].astype(str))\n",
    "    player_b_id = df[\"loser_id\"].astype(str).where(~flip, df[\"winner_id\"].astype(str))\n",
    "    player_a_country = df[\"winner_ioc\"].astype(str).where(~flip, df[\"loser_ioc\"].astype(str))\n",
    "    player_b_country = df[\"loser_ioc\"].astype(str).where(~flip, df[\"winner_ioc\"].astype(str))\n",
    "\n",
    "    matches = pd.DataFrame({\n",
    "        \"match_id\": df[\"match_id\"],\n",
    "        \"date\": df[\"date\"],\n",
    "        \"tournament\": df[\"tourney_name\"].astype(str),\n",
    "        \"city\": df[\"tourney_name\"].astype(str),\n",
    "        \"country\": \"\",\n",
    "        \"level\": df[\"level_norm\"],\n",
    "        \"round\": df[\"round\"].astype(str),\n",
    "        \"best_of_5\": df[\"best_of_5\"],\n",
    "        \"surface\": df[\"surface_norm\"],\n",
    "        \"indoor\": df[\"indoor_flag\"],\n",
    "        \"player_a_id\": player_a_id,\n",
    "        \"player_b_id\": player_b_id,\n",
    "        \"winner_id\": df[\"winner_id\"].astype(str),\n",
    "        \"duration_minutes\": df[\"minutes\"],\n",
    "        \"player_a_country\": player_a_country,\n",
    "        \"player_b_country\": player_b_country,\n",
    "    })\n",
    "    matches = matches.dropna(subset=[\"date\"])\n",
    "    matches = matches[matches[\"surface\"].isin([\"hard\",\"clay\",\"grass\",\"indoor-hard\"])]\n",
    "\n",
    "    # Break points convertits (del rival: faced - saved)\n",
    "    w_bp_conv = (pd.to_numeric(df[\"l_bpFaced\"], errors=\"coerce\") - pd.to_numeric(df[\"l_bpSaved\"], errors=\"coerce\")).clip(lower=0)\n",
    "    l_bp_conv = (pd.to_numeric(df[\"w_bpFaced\"], errors=\"coerce\") - pd.to_numeric(df[\"w_bpSaved\"], errors=\"coerce\")).clip(lower=0)\n",
    "\n",
    "    pts_w = pd.DataFrame({\n",
    "        \"match_id\": df[\"match_id\"],\n",
    "        \"player_id\": df[\"winner_id\"].astype(str),\n",
    "        \"aces\": pd.to_numeric(df[\"w_ace\"], errors=\"coerce\"),\n",
    "        \"double_faults\": pd.to_numeric(df[\"w_df\"], errors=\"coerce\"),     # <-- arreglat\n",
    "        \"first_sv_in\": pd.to_numeric(df[\"w_1stIn\"], errors=\"coerce\"),\n",
    "        \"first_sv_pts_won\": pd.to_numeric(df[\"w_1stWon\"], errors=\"coerce\"),\n",
    "        \"second_sv_pts_won\": pd.to_numeric(df[\"w_2ndWon\"], errors=\"coerce\"),\n",
    "        \"bp_faced\": pd.to_numeric(df[\"w_bpFaced\"], errors=\"coerce\"),\n",
    "        \"bp_saved\": pd.to_numeric(df[\"w_bpSaved\"], errors=\"coerce\"),\n",
    "        \"bp_opp\": pd.to_numeric(df[\"l_bpFaced\"], errors=\"coerce\"),\n",
    "        \"bp_conv\": w_bp_conv,\n",
    "        \"service_games\": pd.to_numeric(df[\"w_SvGms\"], errors=\"coerce\"),\n",
    "        \"return_games\": pd.to_numeric(df[\"l_SvGms\"], errors=\"coerce\"),\n",
    "        \"hold_games_won\": (pd.to_numeric(df[\"w_SvGms\"], errors=\"coerce\") - l_bp_conv).clip(lower=0),\n",
    "        \"break_games_won\": w_bp_conv,\n",
    "        \"tb_played\": np.nan,\n",
    "        \"tb_won\": np.nan\n",
    "    })\n",
    "\n",
    "    pts_l = pd.DataFrame({\n",
    "        \"match_id\": df[\"match_id\"],\n",
    "        \"player_id\": df[\"loser_id\"].astype(str),\n",
    "        \"aces\": pd.to_numeric(df[\"l_ace\"], errors=\"coerce\"),\n",
    "        \"double_faults\": pd.to_numeric(df[\"l_df\"], errors=\"coerce\"),\n",
    "        \"first_sv_in\": pd.to_numeric(df[\"l_1stIn\"], errors=\"coerce\"),\n",
    "        \"first_sv_pts_won\": pd.to_numeric(df[\"l_1stWon\"], errors=\"coerce\"),\n",
    "        \"second_sv_pts_won\": pd.to_numeric(df[\"l_2ndWon\"], errors=\"coerce\"),\n",
    "        \"bp_faced\": pd.to_numeric(df[\"l_bpFaced\"], errors=\"coerce\"),\n",
    "        \"bp_saved\": pd.to_numeric(df[\"l_bpSaved\"], errors=\"coerce\"),\n",
    "        \"bp_opp\": pd.to_numeric(df[\"w_bpFaced\"], errors=\"coerce\"),\n",
    "        \"bp_conv\": l_bp_conv,\n",
    "        \"service_games\": pd.to_numeric(df[\"l_SvGms\"], errors=\"coerce\"),\n",
    "        \"return_games\": pd.to_numeric(df[\"w_SvGms\"], errors=\"coerce\"),\n",
    "        \"hold_games_won\": (pd.to_numeric(df[\"l_SvGms\"], errors=\"coerce\") - w_bp_conv).clip(lower=0),\n",
    "        \"break_games_won\": l_bp_conv,\n",
    "        \"tb_played\": np.nan,\n",
    "        \"tb_won\": np.nan\n",
    "    })\n",
    "\n",
    "    points = pd.concat([pts_w, pts_l], ignore_index=True)\n",
    "    return matches, points\n",
    "\n",
    "\n",
    "def fetch_tml(year_start:int, year_end:int, include_ongoing:bool=True):\n",
    "    frames = []\n",
    "    for y in range(year_start, year_end+1):\n",
    "        url = f\"{RAW_BASE}/{y}.csv\"\n",
    "        try:\n",
    "            df = fetch_csv(url)\n",
    "            df[\"__year\"] = y\n",
    "            frames.append(df)\n",
    "            print(f\"[OK] {y}: {len(df)} rows\")\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] {y}: {e}\")\n",
    "    if include_ongoing:\n",
    "        url = f\"{RAW_BASE}/ongoing_tourneys.csv\"\n",
    "        try:\n",
    "            df_ongo = fetch_csv(url)\n",
    "            df_ongo[\"__year\"] = int(dt.date.today().year)\n",
    "            frames.append(df_ongo)\n",
    "            print(f\"[OK] ongoing_tourneys: {len(df_ongo)} rows\")\n",
    "        except Exception as e:\n",
    "            print(f\"[WARN] ongoing_tourneys: {e}\")\n",
    "    if not frames:\n",
    "        raise RuntimeError(\"No TML data fetched\")\n",
    "    return pd.concat(frames, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22527a3d",
   "metadata": {},
   "source": [
    "## 3) Enriquiment opcional (indoor overrides, país per ciutat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f3ad3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Llista curada d'esdeveniments ATP habitualment 'indoor hard'\n",
    "INDOOR_HARD_TOURNAMENTS = {\n",
    "    # Masters & finals\n",
    "    \"Paris\": True, \"Turin\": True, \"London\": True, \"Milan\": True,\n",
    "    # ATP 500/250 europeus tardor-hivern\n",
    "    \"Basel\": True, \"Vienna\": True, \"Rotterdam\": True, \"Marseille\": True, \"Montpellier\": True,\n",
    "    \"Metz\": True, \"Sofia\": True, \"Antwerp\": True, \"Stockholm\": True, \"Lyon\": True,\n",
    "    # Històrics recents\n",
    "    \"St. Petersburg\": True, \"Moscow\": True, \"Cologne\": True, \"Astana\": True, \"Nur-Sultan\": True\n",
    "}\n",
    "\n",
    "CITY_TO_COUNTRY = {\n",
    "    \"Melbourne\":\"AUS\",\"Sydney\":\"AUS\",\"Adelaide\":\"AUS\",\"Brisbane\":\"AUS\",\n",
    "    \"Paris\":\"FRA\",\"Lyon\":\"FRA\",\"Marseille\":\"FRA\",\"Metz\":\"FRA\",\"Montpellier\":\"FRA\",\n",
    "    \"London\":\"GBR\",\"Birmingham\":\"GBR\",\"Eastbourne\":\"GBR\",\"Nottingham\":\"GBR\",\"Queen's Club\":\"GBR\",\n",
    "    \"Madrid\":\"ESP\",\"Barcelona\":\"ESP\",\"Mallorca\":\"ESP\",\"Valencia\":\"ESP\",\"Sevilla\":\"ESP\",\n",
    "    \"Rome\":\"ITA\",\"Milan\":\"ITA\",\"Turin\":\"ITA\",\"Florence\":\"ITA\",\"Naples\":\"ITA\",\"Palermo\":\"ITA\",\n",
    "    \"Vienna\":\"AUT\",\"Kitzbuhel\":\"AUT\",\"Kitzbühel\":\"AUT\",\n",
    "    \"Basel\":\"CHE\",\"Geneva\":\"CHE\",\"Gstaad\":\"CHE\",\n",
    "    \"Rotterdam\":\"NLD\",\"s-Hertogenbosch\":\"NLD\",\"Amsterdam\":\"NLD\",\"The Hague\":\"NLD\",\n",
    "    \"Antwerp\":\"BEL\",\"Brussels\":\"BEL\",\n",
    "    \"Stockholm\":\"SWE\",\"Bastad\":\"SWE\",\"Båstad\":\"SWE\",\"Gothenburg\":\"SWE\",\n",
    "    \"Hamburg\":\"DEU\",\"Halle\":\"DEU\",\"Stuttgart\":\"DEU\",\"Munich\":\"DEU\",\"Cologne\":\"DEU\",\"Berlin\":\"DEU\",\n",
    "    \"Doha\":\"QAT\",\"Dubai\":\"UAE\",\"Abu Dhabi\":\"UAE\",\n",
    "    \"Indian Wells\":\"USA\",\"Miami\":\"USA\",\"Cincinnati\":\"USA\",\"Washington\":\"USA\",\"Atlanta\":\"USA\",\"Winston-Salem\":\"USA\",\"Newport\":\"USA\",\"Delray Beach\":\"USA\",\"Dallas\":\"USA\",\"Houston\":\"USA\",\"San Jose\":\"USA\",\n",
    "    \"Toronto\":\"CAN\",\"Montreal\":\"CAN\",\"Vancouver\":\"CAN\",\"Quebec City\":\"CAN\",\n",
    "    \"Acapulco\":\"MEX\",\"Los Cabos\":\"MEX\",\"Guadalajara\":\"MEX\",\n",
    "    \"Buenos Aires\":\"ARG\",\"Cordoba\":\"ARG\",\"Santiago\":\"CHL\",\"Rio de Janeiro\":\"BRA\",\"Sao Paulo\":\"BRA\",\"Quito\":\"ECU\",\n",
    "    \"Estoril\":\"PRT\",\"Cascais\":\"PRT\",\"Oeiras\":\"PRT\",\n",
    "    \"Tokyo\":\"JPN\",\"Osaka\":\"JPN\",\n",
    "    \"Beijing\":\"CHN\",\"Shanghai\":\"CHN\",\"Zhuhai\":\"CHN\",\"Chengdu\":\"CHN\",\"Shenzhen\":\"CHN\",\"Wuhan\":\"CHN\",\"Nanchang\":\"CHN\",\"Tianjin\":\"CHN\",\n",
    "    \"Seoul\":\"KOR\",\"Busan\":\"KOR\",\n",
    "    \"Bangkok\":\"THA\",\"Singapore\":\"SGP\",\"Kuala Lumpur\":\"MYS\",\"Pune\":\"IND\",\n",
    "    \"Casablanca\":\"MAR\",\"Marrakech\":\"MAR\",\"Tunis\":\"TUN\",\"Doha\":\"QAT\",\n",
    "    \"Baku\":\"AZE\",\"Astana\":\"KAZ\",\"Nur-Sultan\":\"KAZ\",\n",
    "    \"Basel\":\"CHE\",\"Geneva\":\"CHE\",\n",
    "}\n",
    "def enrich_matches(matches: pd.DataFrame) -> pd.DataFrame:\n",
    "    m = matches.copy()\n",
    "    # Country by city (best-effort)\n",
    "    m[\"country\"] = m.apply(lambda r: CITY_TO_COUNTRY.get(str(r[\"city\"]), r.get(\"country\",\"\")), axis=1)\n",
    "    # Indoor overrides for hard-surface city names\n",
    "    override = m[\"city\"].map(lambda x: INDOOR_HARD_TOURNAMENTS.get(str(x), False))\n",
    "    m.loc[(m[\"surface\"]==\"hard\") & (override.fillna(False)), [\"surface\",\"indoor\"]] = [\"indoor-hard\", 1]\n",
    "    return m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3537c6b",
   "metadata": {},
   "source": [
    "## 4) UI — Paràmetres i Execució"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17db03c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    year_start = widgets.IntText(value=2018, description=\"Any inicial:\")\n",
    "    year_end   = widgets.IntText(value=2025, description=\"Any final:\")\n",
    "    include_ongoing = widgets.Checkbox(value=True, description=\"Incloure ongoing\")\n",
    "    random_flip = widgets.Checkbox(value=True, description=\"Random flip A/B\")\n",
    "    seed = widgets.IntText(value=2025, description=\"Seed\")\n",
    "    data_dir = widgets.Text(value=\"data\", description=\"Data dir:\")\n",
    "    do_enrich = widgets.Checkbox(value=True, description=\"Enriquir (indoor/country)\")\n",
    "    run_btn = widgets.Button(description=\"Fetch & Build\", button_style=\"primary\")\n",
    "    out = widgets.Output()\n",
    "\n",
    "    def on_click(_):\n",
    "        with out:\n",
    "            out.clear_output()\n",
    "            print(\"Baixant TML...\")\n",
    "            df_raw = fetch_tml(year_start.value, year_end.value, include_ongoing.value)\n",
    "            print(\"Construint taules...\")\n",
    "            matches, points = build_from_tml(df_raw, seed=seed.value, do_flip=random_flip.value)\n",
    "            if do_enrich.value:\n",
    "                print(\"Enriquint matches...\")\n",
    "                matches = enrich_matches(matches)\n",
    "            os.makedirs(data_dir.value, exist_ok=True)\n",
    "            mpath = os.path.join(data_dir.value, \"matches.csv\")\n",
    "            ppath = os.path.join(data_dir.value, \"points_sets_games.csv\")\n",
    "            # upsert\n",
    "            if os.path.exists(mpath):\n",
    "                old = pd.read_csv(mpath, dtype=str)\n",
    "                mm = pd.concat([old, matches.astype(str)]).drop_duplicates(subset=[\"match_id\"], keep=\"last\")\n",
    "            else:\n",
    "                mm = matches.astype(str)\n",
    "            mm.to_csv(mpath, index=False)\n",
    "\n",
    "            if os.path.exists(ppath):\n",
    "                oldp = pd.read_csv(ppath, dtype=str)\n",
    "                pp = pd.concat([oldp, points.astype(str)]).drop_duplicates(subset=[\"match_id\",\"player_id\"], keep=\"last\")\n",
    "            else:\n",
    "                pp = points.astype(str)\n",
    "            pp.to_csv(ppath, index=False)\n",
    "\n",
    "            print(f\"✅ Guardat: {mpath}  ({len(mm)} files)\")\n",
    "            print(f\"✅ Guardat: {ppath}  ({len(pp)} files)\")\n",
    "            display(mm.head(5))\n",
    "            display(pp.head(5))\n",
    "\n",
    "    run_btn.on_click(on_click)\n",
    "\n",
    "    widgets.VBox([\n",
    "        widgets.HBox([year_start, year_end]),\n",
    "        widgets.HBox([include_ongoing, random_flip, do_enrich]),\n",
    "        widgets.HBox([seed, data_dir]),\n",
    "        run_btn,\n",
    "        out\n",
    "    ])\n",
    "except Exception as e:\n",
    "    print(\"UI no disponible, executa manualment les funcions fetch_tml(...) i build_from_tml(...)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8db9362b-2406-4863-b0e7-9e3df026db2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] 2018: 2926 rows\n",
      "[OK] 2019: 2806 rows\n",
      "[OK] 2020: 1466 rows\n",
      "[OK] 2021: 2735 rows\n",
      "[OK] 2022: 2918 rows\n",
      "[OK] 2023: 2995 rows\n",
      "[OK] 2024: 3076 rows\n",
      "[OK] 2025: 2648 rows\n",
      "[OK] ongoing_tourneys: 81 rows\n",
      "✅ Guardat: ./matches.csv (files: 21598)\n",
      "✅ Guardat: ./points_sets_games.csv (files: 43302)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>date</th>\n",
       "      <th>tournament</th>\n",
       "      <th>city</th>\n",
       "      <th>country</th>\n",
       "      <th>level</th>\n",
       "      <th>round</th>\n",
       "      <th>best_of_5</th>\n",
       "      <th>surface</th>\n",
       "      <th>indoor</th>\n",
       "      <th>player_a_id</th>\n",
       "      <th>player_b_id</th>\n",
       "      <th>winner_id</th>\n",
       "      <th>duration_minutes</th>\n",
       "      <th>player_a_country</th>\n",
       "      <th>player_b_country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-339_1.0_2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>AUS</td>\n",
       "      <td>ATP</td>\n",
       "      <td>R32</td>\n",
       "      <td>0</td>\n",
       "      <td>hard</td>\n",
       "      <td>0</td>\n",
       "      <td>MH30</td>\n",
       "      <td>PB22</td>\n",
       "      <td>MH30</td>\n",
       "      <td>95.0</td>\n",
       "      <td>AUS</td>\n",
       "      <td>CAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-339_2.0_2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>AUS</td>\n",
       "      <td>ATP</td>\n",
       "      <td>R32</td>\n",
       "      <td>0</td>\n",
       "      <td>hard</td>\n",
       "      <td>0</td>\n",
       "      <td>SU55</td>\n",
       "      <td>E831</td>\n",
       "      <td>E831</td>\n",
       "      <td>150.0</td>\n",
       "      <td>CAN</td>\n",
       "      <td>GBR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-339_3.0_2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>AUS</td>\n",
       "      <td>ATP</td>\n",
       "      <td>R32</td>\n",
       "      <td>0</td>\n",
       "      <td>hard</td>\n",
       "      <td>0</td>\n",
       "      <td>MA30</td>\n",
       "      <td>CH27</td>\n",
       "      <td>CH27</td>\n",
       "      <td>99.0</td>\n",
       "      <td>LUX</td>\n",
       "      <td>KOR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-339_4.0_2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>AUS</td>\n",
       "      <td>ATP</td>\n",
       "      <td>R32</td>\n",
       "      <td>0</td>\n",
       "      <td>hard</td>\n",
       "      <td>0</td>\n",
       "      <td>E690</td>\n",
       "      <td>TD51</td>\n",
       "      <td>E690</td>\n",
       "      <td>59.0</td>\n",
       "      <td>AUS</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-339_5.0_2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>AUS</td>\n",
       "      <td>ATP</td>\n",
       "      <td>R32</td>\n",
       "      <td>0</td>\n",
       "      <td>hard</td>\n",
       "      <td>0</td>\n",
       "      <td>E873</td>\n",
       "      <td>Z184</td>\n",
       "      <td>Z184</td>\n",
       "      <td>72.0</td>\n",
       "      <td>MEX</td>\n",
       "      <td>ARG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  match_id        date tournament      city country level  \\\n",
       "0  2018-339_1.0_2018-01-01  2018-01-01   Brisbane  Brisbane     AUS   ATP   \n",
       "1  2018-339_2.0_2018-01-01  2018-01-01   Brisbane  Brisbane     AUS   ATP   \n",
       "2  2018-339_3.0_2018-01-01  2018-01-01   Brisbane  Brisbane     AUS   ATP   \n",
       "3  2018-339_4.0_2018-01-01  2018-01-01   Brisbane  Brisbane     AUS   ATP   \n",
       "4  2018-339_5.0_2018-01-01  2018-01-01   Brisbane  Brisbane     AUS   ATP   \n",
       "\n",
       "  round best_of_5 surface indoor player_a_id player_b_id winner_id  \\\n",
       "0   R32         0    hard      0        MH30        PB22      MH30   \n",
       "1   R32         0    hard      0        SU55        E831      E831   \n",
       "2   R32         0    hard      0        MA30        CH27      CH27   \n",
       "3   R32         0    hard      0        E690        TD51      E690   \n",
       "4   R32         0    hard      0        E873        Z184      Z184   \n",
       "\n",
       "  duration_minutes player_a_country player_b_country  \n",
       "0             95.0              AUS              CAN  \n",
       "1            150.0              CAN              GBR  \n",
       "2             99.0              LUX              KOR  \n",
       "3             59.0              AUS              USA  \n",
       "4             72.0              MEX              ARG  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>player_id</th>\n",
       "      <th>aces</th>\n",
       "      <th>double_faults</th>\n",
       "      <th>first_sv_in</th>\n",
       "      <th>first_sv_pts_won</th>\n",
       "      <th>second_sv_pts_won</th>\n",
       "      <th>bp_faced</th>\n",
       "      <th>bp_saved</th>\n",
       "      <th>bp_opp</th>\n",
       "      <th>bp_conv</th>\n",
       "      <th>service_games</th>\n",
       "      <th>return_games</th>\n",
       "      <th>hold_games_won</th>\n",
       "      <th>break_games_won</th>\n",
       "      <th>tb_played</th>\n",
       "      <th>tb_won</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-339_1.0_2018-01-01</td>\n",
       "      <td>MH30</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-339_2.0_2018-01-01</td>\n",
       "      <td>E831</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-339_3.0_2018-01-01</td>\n",
       "      <td>CH27</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-339_4.0_2018-01-01</td>\n",
       "      <td>E690</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-339_5.0_2018-01-01</td>\n",
       "      <td>Z184</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  match_id player_id  aces double_faults first_sv_in  \\\n",
       "0  2018-339_1.0_2018-01-01      MH30   8.0           0.0        37.0   \n",
       "1  2018-339_2.0_2018-01-01      E831   5.0           5.0        65.0   \n",
       "2  2018-339_3.0_2018-01-01      CH27   7.0           4.0        35.0   \n",
       "3  2018-339_4.0_2018-01-01      E690   7.0           1.0        32.0   \n",
       "4  2018-339_5.0_2018-01-01      Z184  12.0           3.0        37.0   \n",
       "\n",
       "  first_sv_pts_won second_sv_pts_won bp_faced bp_saved bp_opp bp_conv  \\\n",
       "0             27.0              17.0      1.0      1.0   10.0     3.0   \n",
       "1             54.0              29.0      6.0      5.0    3.0     2.0   \n",
       "2             29.0              17.0      2.0      2.0    5.0     2.0   \n",
       "3             23.0              11.0      3.0      2.0    5.0     4.0   \n",
       "4             31.0              11.0      1.0      1.0    6.0     2.0   \n",
       "\n",
       "  service_games return_games hold_games_won break_games_won tb_played tb_won  \n",
       "0           9.0          9.0            9.0             3.0       nan    nan  \n",
       "1          17.0         17.0           16.0             2.0       nan    nan  \n",
       "2          10.0         11.0           10.0             2.0       nan    nan  \n",
       "3           9.0          8.0            8.0             4.0       nan    nan  \n",
       "4          10.0          9.0           10.0             2.0       nan    nan  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Paràmetres\n",
    "YEAR_START = 2018\n",
    "YEAR_END   = 2025\n",
    "INCLUDE_ONGOING = True\n",
    "RANDOM_FLIP = True\n",
    "SEED = 2025\n",
    "DATA_DIR = \".\"\n",
    "\n",
    "# 1) baixa i concatena TML\n",
    "df_raw = fetch_tml(YEAR_START, YEAR_END, include_ongoing=INCLUDE_ONGOING)\n",
    "\n",
    "# 2) construeix taules\n",
    "matches, points = build_from_tml(df_raw, seed=SEED, do_flip=RANDOM_FLIP)\n",
    "\n",
    "# 3) enriquiment (opc.)\n",
    "matches = enrich_matches(matches)\n",
    "\n",
    "# 4) desa (amb upsert)\n",
    "import os, pandas as pd\n",
    "os.makedirs(DATA_DIR, exist_ok=True)\n",
    "mpath = os.path.join(DATA_DIR, \"matches.csv\")\n",
    "ppath = os.path.join(DATA_DIR, \"points_sets_games.csv\")\n",
    "\n",
    "if os.path.exists(mpath):\n",
    "    old = pd.read_csv(mpath, dtype=str)\n",
    "    mm = pd.concat([old, matches.astype(str)]).drop_duplicates(subset=[\"match_id\"], keep=\"last\")\n",
    "else:\n",
    "    mm = matches.astype(str)\n",
    "mm.to_csv(mpath, index=False)\n",
    "\n",
    "if os.path.exists(ppath):\n",
    "    oldp = pd.read_csv(ppath, dtype=str)\n",
    "    pp = pd.concat([oldp, points.astype(str)]).drop_duplicates(subset=[\"match_id\",\"player_id\"], keep=\"last\")\n",
    "else:\n",
    "    pp = points.astype(str)\n",
    "pp.to_csv(ppath, index=False)\n",
    "\n",
    "print(f\"✅ Guardat: {mpath} (files: {len(mm)})\")\n",
    "print(f\"✅ Guardat: {ppath} (files: {len(pp)})\")\n",
    "display(mm.head(5))\n",
    "display(pp.head(5))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
