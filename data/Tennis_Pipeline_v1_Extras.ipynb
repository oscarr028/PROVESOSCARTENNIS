{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f638918",
   "metadata": {},
   "source": [
    "# Tennis Pipeline — Extras\n",
    "Aquest notebook afegeix LightGBM, calibració isotònica, rolling CV i backtest de profit amb odds si estan disponibles.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6baee96",
   "metadata": {},
   "source": [
    "## 0) Dependències"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "743bf747",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# !pip install lightgbm -q\n",
    "import os, pandas as pd, numpy as np, json, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import log_loss, roc_auc_score, brier_score_loss\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "try:\n",
    "    import lightgbm as lgb\n",
    "except Exception as e:\n",
    "    print(\"⚠️ lightgbm no disponible. Instal·la-ho amb pip i reinicia el kernel.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d87d598",
   "metadata": {},
   "source": [
    "## 1) Carrega dataset i columnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8db7e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CWD: /Users/adriaparcerisas/Downloads/data\n",
      "Exists dataset? True\n",
      "✔️ model_columns: 22\n",
      "Dataset shape (raw): (24934, 26)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>match_id</th>\n",
       "      <th>date</th>\n",
       "      <th>surface</th>\n",
       "      <th>elo_global_pre_diff</th>\n",
       "      <th>elo_surface_pre_diff</th>\n",
       "      <th>winrate10_pre_diff</th>\n",
       "      <th>winrate25_pre_diff</th>\n",
       "      <th>sos_elo_recent_pre_diff</th>\n",
       "      <th>hold_pre_diff</th>\n",
       "      <th>break_pre_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>first_in_pre_diff</th>\n",
       "      <th>first_pts_pre_diff</th>\n",
       "      <th>second_pts_pre_diff</th>\n",
       "      <th>is_indoor</th>\n",
       "      <th>is_best_of_5</th>\n",
       "      <th>surface_hard</th>\n",
       "      <th>surface_clay</th>\n",
       "      <th>surface_grass</th>\n",
       "      <th>surface_indoor-hard</th>\n",
       "      <th>y_home_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-339_1.0_2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>hard</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-339_2.0_2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>hard</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-339_3.0_2018-01-01</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>hard</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  match_id       date surface  elo_global_pre_diff  \\\n",
       "0  2018-339_1.0_2018-01-01 2018-01-01    hard                  0.0   \n",
       "1  2018-339_2.0_2018-01-01 2018-01-01    hard                  0.0   \n",
       "2  2018-339_3.0_2018-01-01 2018-01-01    hard                  0.0   \n",
       "\n",
       "   elo_surface_pre_diff  winrate10_pre_diff  winrate25_pre_diff  \\\n",
       "0                   0.0                 NaN                 NaN   \n",
       "1                   0.0                 NaN                 NaN   \n",
       "2                   0.0                 NaN                 NaN   \n",
       "\n",
       "   sos_elo_recent_pre_diff  hold_pre_diff  break_pre_diff  ...  \\\n",
       "0                      NaN            NaN             NaN  ...   \n",
       "1                      NaN            NaN             NaN  ...   \n",
       "2                      NaN            NaN             NaN  ...   \n",
       "\n",
       "   first_in_pre_diff  first_pts_pre_diff  second_pts_pre_diff  is_indoor  \\\n",
       "0                NaN                 NaN                  NaN          0   \n",
       "1                NaN                 NaN                  NaN          0   \n",
       "2                NaN                 NaN                  NaN          0   \n",
       "\n",
       "   is_best_of_5  surface_hard  surface_clay  surface_grass  \\\n",
       "0             0             1             0              0   \n",
       "1             0             1             0              0   \n",
       "2             0             1             0              0   \n",
       "\n",
       "   surface_indoor-hard  y_home_win  \n",
       "0                    0           1  \n",
       "1                    0           0  \n",
       "2                    0           0  \n",
       "\n",
       "[3 rows x 26 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os, pandas as pd\n",
    "\n",
    "DATASET_PATH = \"outputs/dataset_match_level.csv\"\n",
    "COLS_PATH = \"outputs/model_columns.txt\"\n",
    "\n",
    "# Sanity check\n",
    "print(\"CWD:\", os.getcwd())\n",
    "print(\"Exists dataset?\", os.path.exists(DATASET_PATH))\n",
    "\n",
    "dataset = pd.read_csv(DATASET_PATH)\n",
    "dataset['date'] = pd.to_datetime(dataset['date'], errors='coerce')\n",
    "\n",
    "try:\n",
    "    model_cols = pd.read_csv(COLS_PATH, header=None)[0].tolist()\n",
    "    print(\"✔️ model_columns:\", len(model_cols))\n",
    "except FileNotFoundError:\n",
    "    no_feat = {'match_id','date','surface','y_home_win'}\n",
    "    model_cols = [c for c in dataset.columns if c not in no_feat]\n",
    "    os.makedirs(\"outputs\", exist_ok=True)\n",
    "    pd.Series(model_cols).to_csv(COLS_PATH, index=False, header=False)\n",
    "    print(\"⚠️ creat model_columns.txt amb\", len(model_cols), \"features\")\n",
    "\n",
    "print(\"Dataset shape (raw):\", dataset.shape)\n",
    "display(dataset.head(3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87ce97e",
   "metadata": {},
   "source": [
    "## 2) Splits temporals automàtics (80/10/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69815c03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows totals=24934, amb data vàlida=24934\n",
      "train n=19971 | dates: 2018-01-01 00:00:00 → 2025-04-14 00:00:00\n",
      "valid n=3173 | dates: 2025-04-21 00:00:00 → 2025-08-24 00:00:00\n",
      "test n=1790 | dates: 2025-09-12 00:00:00 → 2025-10-13 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Split temporal robust (80/10/10) amb fallback\n",
    "import pandas as pd\n",
    "df = dataset.copy()\n",
    "\n",
    "# Assegura dates parsejades i compta files vàlides\n",
    "df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "n_total = len(df)\n",
    "n_dates = df['date'].notna().sum()\n",
    "print(f\"Rows totals={n_total}, amb data vàlida={n_dates}\")\n",
    "\n",
    "if n_dates == 0:\n",
    "    # Fallback per índex si no hi ha dates vàlides\n",
    "    idx80 = int(0.80*n_total); idx90 = int(0.90*n_total)\n",
    "    train, valid, test = df.iloc[:idx80], df.iloc[idx80:idx90], df.iloc[idx90:]\n",
    "else:\n",
    "    # Treu NaT, ordena per data i calcula quantils\n",
    "    df = df.dropna(subset=['date']).sort_values('date').reset_index(drop=True)\n",
    "    q80 = df['date'].quantile(0.80)\n",
    "    q90 = df['date'].quantile(0.90)\n",
    "\n",
    "    TRAIN_END = pd.Timestamp(q80).normalize()\n",
    "    VALID_END = pd.Timestamp(q90).normalize()\n",
    "\n",
    "    train = df[df['date'] <= TRAIN_END].copy()\n",
    "    valid = df[(df['date'] > TRAIN_END) & (df['date'] <= VALID_END)].copy()\n",
    "    test  = df[df['date'] > VALID_END].copy()\n",
    "\n",
    "    # Si el TEST queda buit (dates molt concentrades), forcem un tall per percentils\n",
    "    if len(test) == 0:\n",
    "        cut80 = int(0.80*len(df)); cut90 = int(0.90*len(df))\n",
    "        train, valid, test = df.iloc[:cut80].copy(), df.iloc[cut80:cut90].copy(), df.iloc[cut90:].copy()\n",
    "\n",
    "for name, d in [('train',train),('valid',valid),('test',test)]:\n",
    "    print(name, f\"n={len(d)} | dates: {d['date'].min()} → {d['date'].max()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c2fa6",
   "metadata": {},
   "source": [
    "## 3) LightGBM — entrenament amb early stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bcf8c9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 10014, number of negative: 9957\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000259 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 719\n",
      "[LightGBM] [Info] Number of data points in the train set: 19971, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501427 -> initscore=0.005708\n",
      "[LightGBM] [Info] Start training from score 0.005708\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[60]\tvalid_0's binary_logloss: 0.600318\n",
      "{\n",
      "  \"train_logloss\": 0.6175858793492155,\n",
      "  \"valid_logloss\": 0.6003175941888154,\n",
      "  \"valid_auc\": 0.7356281786395422,\n",
      "  \"valid_brier\": 0.20688993483674545,\n",
      "  \"best_iter\": 60\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb, numpy as np, json\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.metrics import log_loss, roc_auc_score, brier_score_loss\n",
    "\n",
    "X_tr = train[model_cols].fillna(0.0).values\n",
    "y_tr = train['y_home_win'].values\n",
    "X_va = valid[model_cols].fillna(0.0).values\n",
    "y_va = valid['y_home_win'].values\n",
    "\n",
    "clf = LGBMClassifier(\n",
    "    n_estimators=5000,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=63,\n",
    "    subsample=0.9,\n",
    "    colsample_bytree=0.9,\n",
    "    min_child_samples=50,\n",
    "    objective='binary',\n",
    "    random_state=2025,\n",
    ")\n",
    "clf.fit(\n",
    "    X_tr, y_tr,\n",
    "    eval_set=[(X_va, y_va)],\n",
    "    eval_metric='logloss',\n",
    "    callbacks=[lgb.early_stopping(100), lgb.log_evaluation(200)],\n",
    ")\n",
    "\n",
    "p_tr = clf.predict_proba(X_tr)[:,1]\n",
    "p_va = clf.predict_proba(X_va)[:,1]\n",
    "print(json.dumps({\n",
    "    \"train_logloss\": float(log_loss(y_tr, p_tr)),\n",
    "    \"valid_logloss\": float(log_loss(y_va, p_va)),\n",
    "    \"valid_auc\": float(roc_auc_score(y_va, p_va)),\n",
    "    \"valid_brier\": float(brier_score_loss(y_va, p_va)),\n",
    "    \"best_iter\": int(clf.best_iteration_ if hasattr(clf,\"best_iteration_\") else clf.n_estimators),\n",
    "}, indent=2))\n",
    "\n",
    "# Per coherència amb la resta del notebook:\n",
    "gbm = clf  # així les cel·les següents poden usar `gbm`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11acee9",
   "metadata": {},
   "source": [
    "## 4) Calibració Isotònica i Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a6e15f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'valid_logloss': 0.6003175941888154, 'valid_brier': 0.20688993483674545, 'valid_auc': 0.7356281786395422, 'valid_logloss_cal': 0.5632387915475144, 'valid_brier_cal': 0.19345896591941117}\n",
      "{'test_logloss': 0.6576110131813113, 'test_brier': 0.23260203472545973, 'test_auc': 0.6462303010975577, 'test_logloss_cal': 0.7225148939750938, 'test_brier_cal': 0.23667086508865018}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "from sklearn.metrics import log_loss, roc_auc_score, brier_score_loss\n",
    "\n",
    "def predict_proba_robust(model, X):\n",
    "    \"\"\"Retorna p(class=1) funcionant tant per Booster com per LGBMClassifier.\"\"\"\n",
    "    # API core (Booster)\n",
    "    if hasattr(model, \"predict\") and hasattr(model, \"best_iteration\") and not hasattr(model, \"predict_proba\"):\n",
    "        try:\n",
    "            return model.predict(X, num_iteration=model.best_iteration)\n",
    "        except TypeError:\n",
    "            return model.predict(X)\n",
    "    # API sklearn\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        kwargs = {}\n",
    "        if hasattr(model, \"best_iteration_\"):\n",
    "            kwargs[\"num_iteration\"] = model.best_iteration_\n",
    "        return model.predict_proba(X, **kwargs)[:, 1]\n",
    "    # Últim recurs\n",
    "    p = model.predict(X)\n",
    "    return p if p.ndim == 1 else p[:, 1]\n",
    "\n",
    "# --- VALID: ja tens p_va de l’entrenament; si no, el recalcularem de forma segura\n",
    "try:\n",
    "    p_va  # existent?\n",
    "except NameError:\n",
    "    X_va = valid[model_cols].fillna(0.0).values\n",
    "    p_va = predict_proba_robust(gbm, X_va)\n",
    "\n",
    "y_va = valid['y_home_win'].values\n",
    "\n",
    "# Calibració isotònica sobre VALID\n",
    "iso = IsotonicRegression(out_of_bounds='clip').fit(p_va, y_va)\n",
    "p_va_cal = iso.transform(p_va)\n",
    "\n",
    "print({\n",
    "    \"valid_logloss\": float(log_loss(y_va, np.clip(p_va, 1e-6, 1-1e-6))),\n",
    "    \"valid_brier\": float(brier_score_loss(y_va, p_va)),\n",
    "    \"valid_auc\": float(roc_auc_score(y_va, p_va)),\n",
    "    \"valid_logloss_cal\": float(log_loss(y_va, np.clip(p_va_cal, 1e-6, 1-1e-6))),\n",
    "    \"valid_brier_cal\": float(brier_score_loss(y_va, p_va_cal)),\n",
    "})\n",
    "\n",
    "# --- TEST\n",
    "if len(test):\n",
    "    X_te = test[model_cols].fillna(0.0).values\n",
    "    y_te = test['y_home_win'].values\n",
    "    p_te = predict_proba_robust(gbm, X_te)\n",
    "    p_te_cal = iso.transform(p_te)\n",
    "\n",
    "    print({\n",
    "        \"test_logloss\": float(log_loss(y_te, np.clip(p_te, 1e-6, 1-1e-6))),\n",
    "        \"test_brier\": float(brier_score_loss(y_te, p_te)),\n",
    "        \"test_auc\": float(roc_auc_score(y_te, p_te)),\n",
    "        \"test_logloss_cal\": float(log_loss(y_te, np.clip(p_te_cal, 1e-6, 1-1e-6))),\n",
    "        \"test_brier_cal\": float(brier_score_loss(y_te, p_te_cal)),\n",
    "    })\n",
    "else:\n",
    "    print(\"⚠️ TEST buit; reporto només VALID.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e46ad2",
   "metadata": {},
   "source": [
    "## 5) Rolling Time CV (3 folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "559e913e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 6203, number of negative: 6264\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000502 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 12467, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.497554 -> initscore=-0.009786\n",
      "[LightGBM] [Info] Start training from score -0.009786\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's binary_logloss: 0.645412\n",
      "[LightGBM] [Info] Number of positive: 8318, number of negative: 8304\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000083 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 715\n",
      "[LightGBM] [Info] Number of data points in the train set: 16622, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500421 -> initscore=0.001685\n",
      "[LightGBM] [Info] Start training from score 0.001685\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's binary_logloss: 0.65012\n",
      "[LightGBM] [Info] Number of positive: 10421, number of negative: 10356\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000102 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 719\n",
      "[LightGBM] [Info] Number of data points in the train set: 20777, number of used features: 10\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.501564 -> initscore=0.006257\n",
      "[LightGBM] [Info] Start training from score 0.006257\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's binary_logloss: 0.612301\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>n_train</th>\n",
       "      <th>n_valid</th>\n",
       "      <th>logloss</th>\n",
       "      <th>brier</th>\n",
       "      <th>auc</th>\n",
       "      <th>best_iter</th>\n",
       "      <th>train_end</th>\n",
       "      <th>valid_start</th>\n",
       "      <th>valid_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>12467</td>\n",
       "      <td>4155</td>\n",
       "      <td>0.645412</td>\n",
       "      <td>0.227165</td>\n",
       "      <td>0.672290</td>\n",
       "      <td>46</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>2022-09-26</td>\n",
       "      <td>2024-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>16622</td>\n",
       "      <td>4155</td>\n",
       "      <td>0.650120</td>\n",
       "      <td>0.229298</td>\n",
       "      <td>0.664993</td>\n",
       "      <td>37</td>\n",
       "      <td>2024-03-04</td>\n",
       "      <td>2024-03-04</td>\n",
       "      <td>2025-07-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>20777</td>\n",
       "      <td>4157</td>\n",
       "      <td>0.612301</td>\n",
       "      <td>0.212286</td>\n",
       "      <td>0.714252</td>\n",
       "      <td>77</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-07-21</td>\n",
       "      <td>2025-10-13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  n_train  n_valid   logloss     brier       auc  best_iter  \\\n",
       "0     1    12467     4155  0.645412  0.227165  0.672290         46   \n",
       "1     2    16622     4155  0.650120  0.229298  0.664993         37   \n",
       "2     3    20777     4157  0.612301  0.212286  0.714252         77   \n",
       "\n",
       "    train_end valid_start   valid_end  \n",
       "0  2022-09-26  2022-09-26  2024-03-04  \n",
       "1  2024-03-04  2024-03-04  2025-07-21  \n",
       "2  2025-07-21  2025-07-21  2025-10-13  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mitjanes: {'logloss': 0.6359445164603192, 'auc': 0.6838448978852844, 'brier': 0.22291628463895066}\n"
     ]
    }
   ],
   "source": [
    "# Rolling Time CV (LightGBM sklearn + callbacks), robust a NA i splits petits\n",
    "import pandas as pd, numpy as np\n",
    "from lightgbm import LGBMClassifier, early_stopping, log_evaluation\n",
    "from sklearn.metrics import log_loss, roc_auc_score, brier_score_loss\n",
    "\n",
    "def rolling_time_cv(df, model_cols, n_folds=3, min_train_frac=0.5, random_state=2025):\n",
    "    df = df.copy()\n",
    "    # Dates i ordre temporal\n",
    "    df['date'] = pd.to_datetime(df['date'], errors='coerce')\n",
    "    df = df.dropna(subset=['date']).sort_values('date').reset_index(drop=True)\n",
    "    n = len(df)\n",
    "    if n == 0:\n",
    "        print(\"⚠️ Dataset buit després de netejar dates.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    start = max(1, int(n * float(min_train_frac)))\n",
    "    fold_size = max(1, (n - start) // max(1, n_folds))\n",
    "    rows = []\n",
    "\n",
    "    for k in range(n_folds):\n",
    "        val_start = start + k * fold_size\n",
    "        val_end = start + (k + 1) * fold_size if k < n_folds - 1 else n\n",
    "        if val_start >= n:\n",
    "            break\n",
    "\n",
    "        tr = df.iloc[:val_start]\n",
    "        va = df.iloc[val_start:val_end]\n",
    "        if len(va) == 0 or len(tr) == 0 or len(np.unique(tr['y_home_win'])) < 2:\n",
    "            # salta si no hi ha prou dades o només una classe al train\n",
    "            continue\n",
    "\n",
    "        X_tr = tr[model_cols].fillna(0.0).values\n",
    "        y_tr = tr['y_home_win'].values\n",
    "        X_va = va[model_cols].fillna(0.0).values\n",
    "        y_va = va['y_home_win'].values\n",
    "\n",
    "        clf = LGBMClassifier(\n",
    "            n_estimators=5000,\n",
    "            learning_rate=0.05,\n",
    "            num_leaves=63,\n",
    "            subsample=0.9,\n",
    "            colsample_bytree=0.9,\n",
    "            min_child_samples=50,\n",
    "            objective='binary',\n",
    "            random_state=random_state,\n",
    "        )\n",
    "\n",
    "        clf.fit(\n",
    "            X_tr, y_tr,\n",
    "            eval_set=[(X_va, y_va)],\n",
    "            eval_metric='logloss',\n",
    "            callbacks=[early_stopping(100), log_evaluation(0)],\n",
    "        )\n",
    "\n",
    "        # Prediccions amb millor iteració si existeix\n",
    "        if hasattr(clf, \"best_iteration_\"):\n",
    "            p_va = clf.predict_proba(X_va, num_iteration=clf.best_iteration_)[:, 1]\n",
    "            best_iter = int(clf.best_iteration_)\n",
    "        else:\n",
    "            p_va = clf.predict_proba(X_va)[:, 1]\n",
    "            best_iter = int(clf.n_estimators)\n",
    "\n",
    "        # Mètriques (AUC robust)\n",
    "        try:\n",
    "            auc = roc_auc_score(y_va, p_va)\n",
    "        except ValueError:\n",
    "            auc = float(\"nan\")\n",
    "\n",
    "        rows.append(dict(\n",
    "            fold=k+1,\n",
    "            n_train=len(tr), n_valid=len(va),\n",
    "            logloss=float(log_loss(y_va, np.clip(p_va, 1e-6, 1-1e-6))),\n",
    "            brier=float(brier_score_loss(y_va, p_va)),\n",
    "            auc=float(auc),\n",
    "            best_iter=best_iter,\n",
    "            train_end=str(tr['date'].max().date()),\n",
    "            valid_start=str(va['date'].min().date()),\n",
    "            valid_end=str(va['date'].max().date()),\n",
    "        ))\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# Executa el CV\n",
    "cv = rolling_time_cv(dataset[['date','y_home_win'] + model_cols].copy(), model_cols, n_folds=3, min_train_frac=0.5)\n",
    "display(cv)\n",
    "if len(cv):\n",
    "    print(\"Mitjanes:\", cv[['logloss','auc','brier']].mean().to_dict())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f2f26b",
   "metadata": {},
   "source": [
    "## 6) Backtest de profit (si hi ha odds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5dc7b141",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- Prediccions per al TEST (sense scaler) + opcionalment calibrades ---\n",
    "import numpy as np\n",
    "\n",
    "def predict_proba_robust(model, X):\n",
    "    \"\"\"Retorna p(class=1) per Booster o LGBMClassifier.\"\"\"\n",
    "    # Core Booster\n",
    "    if hasattr(model, \"predict\") and hasattr(model, \"best_iteration\") and not hasattr(model, \"predict_proba\"):\n",
    "        try:\n",
    "            return model.predict(X, num_iteration=model.best_iteration)\n",
    "        except TypeError:\n",
    "            return model.predict(X)\n",
    "    # sklearn\n",
    "    if hasattr(model, \"predict_proba\"):\n",
    "        if hasattr(model, \"best_iteration_\"):\n",
    "            try:\n",
    "                return model.predict_proba(X, num_iteration=model.best_iteration_)[:, 1]\n",
    "            except TypeError:\n",
    "                return model.predict_proba(X)[:, 1]\n",
    "        else:\n",
    "            return model.predict_proba(X)[:, 1]\n",
    "    # fallback\n",
    "    p = model.predict(X)\n",
    "    return p if p.ndim == 1 else p[:, 1]\n",
    "\n",
    "X_te = test[model_cols].fillna(0.0).values\n",
    "test = test.copy()\n",
    "\n",
    "# prediccions \"raw\"\n",
    "p_raw = predict_proba_robust(gbm, X_te)\n",
    "\n",
    "# si tens l'objecte de calibració 'iso', aplica'l; si no, usa p_raw\n",
    "p_cal = iso.transform(p_raw) if 'iso' in globals() else p_raw\n",
    "test['p'] = np.clip(p_cal, 1e-6, 1-1e-6)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571375b6",
   "metadata": {},
   "source": [
    "## 7) Guarda model i scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d1c5b8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Desat a 'outputs/'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import joblib, os\n",
    "if 'lgb' in globals():\n",
    "    os.makedirs('outputs', exist_ok=True)\n",
    "    joblib.dump(gbm, 'outputs/model_lightgbm.pkl')\n",
    "    joblib.dump(scaler, 'outputs/scaler.pkl')\n",
    "    print(\"Desat a 'outputs/'\")\n",
    "else:\n",
    "    print(\"Sense LightGBM; res per desar.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
